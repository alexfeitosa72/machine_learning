{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h1 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:#005097; border:0' role=\"tab\" aria-controls=\"home\"><center>APRENDIZADO DE MÁQUINA (CIC1205/GCC1932) - Trabalho 1</center></h1>\n",
    "\n",
    "- Nome completo: <ALEXANDER_RAMOS_FEITOSA>\n",
    "- [Link para vídeo](<LINK_VIDEO>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Predição de pagamento de empréstimos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise exploratória dos conjuntos de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Definição do dicionário de dados\n",
    "column_mapping = {\n",
    "    0: \"ESCT\",    # Estado civil\n",
    "    1: \"NDEP\",    # Número de dependentes\n",
    "    2: \"RENDA\",   # Renda Familiar\n",
    "    3: \"TIPOR\",   # Tipo de residência\n",
    "    4: \"VBEM\",    # Valor do bem a ser adquirido\n",
    "    5: \"NPARC\",   # Número de parcelas\n",
    "    6: \"VPARC\",   # Valor da parcela\n",
    "    7: \"TEL\",     # Se possui telefone\n",
    "    8: \"IDADE\",   # Idade do cliente\n",
    "    9: \"RESMS\",   # Tempo de moradia (meses)\n",
    "    10: \"ENTRADA\", # Valor da entrada\n",
    "    11: \"CLASSE\"  # Cliente pagou a dívida (1=sim)\n",
    "}\n",
    "\n",
    "# Leitura dos arquivos\n",
    "train_path = \"data/credtrain.txt\"\n",
    "test_path = \"data/credtest.txt\"\n",
    "\n",
    "# Leitura com nomes das colunas\n",
    "df_train = pd.read_csv(train_path, sep=\"\\t\", header=None).rename(columns=column_mapping)\n",
    "df_test = pd.read_csv(test_path, sep=\"\\t\", header=None).rename(columns=column_mapping)\n",
    "\n",
    "# Análise exploratória inicial\n",
    "print(\"=== Análise dos Conjuntos de Dados ===\")\n",
    "print(\"\\nInformações do conjunto de treinamento:\")\n",
    "print(df_train.info())\n",
    "\n",
    "print(\"\\nInformações do conjunto de teste:\")\n",
    "print(df_test.info())\n",
    "\n",
    "# Verificação do balanceamento das classes\n",
    "print(\"\\n=== Distribuição das Classes ===\")\n",
    "print(\"\\nConjunto de treinamento:\")\n",
    "print(df_train[\"CLASSE\"].value_counts(normalize=True).round(3))\n",
    "print(\"\\nConjunto de teste:\")\n",
    "print(df_test[\"CLASSE\"].value_counts(normalize=True).round(3))\n",
    "\n",
    "# Análise das distribuições das variáveis numéricas\n",
    "numerical_cols = [\"RENDA\", \"VBEM\", \"NPARC\", \"VPARC\", \"IDADE\", \"RESMS\", \"ENTRADA\"]\n",
    "\n",
    "# Criar subplots para cada variável numérica\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Plotar distribuições\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    sns.histplot(data=df_train, x=col, ax=axes[idx], kde=True)\n",
    "    axes[idx].set_title(f'Distribuição de {col}')\n",
    "    axes[idx].set_xlabel(col)\n",
    "\n",
    "# Remover subplot extra\n",
    "axes[-1].remove()\n",
    "axes[-2].remove()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento das variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das variáveis categóricas\n",
    "categorical_features = ['ESCT', 'TIPOR', 'TEL', 'NDEP']\n",
    "\n",
    "# Copia dos dataframes para não modificar os originais\n",
    "y_train = df_train['CLASSE'].copy()\n",
    "y_test = df_test['CLASSE'].copy()\n",
    "X_train_prep = df_train.drop('CLASSE', axis=1).copy()\n",
    "X_test_prep = df_test.drop('CLASSE', axis=1).copy()\n",
    "\n",
    "# One-Hot Encoding para todas as variáveis categóricas\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit e transform no conjunto de treino\n",
    "categorical_encoded = ohe.fit_transform(X_train_prep[categorical_features])\n",
    "\n",
    "# Criar nomes para as novas colunas\n",
    "feature_names = []\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    categories = ohe.categories_[i][1:]\n",
    "    feature_names.extend([f\"{feature}_{cat}\" for cat in categories])\n",
    "\n",
    "# Adicionar colunas encoded ao DataFrame de treino\n",
    "encoded_df_train = pd.DataFrame(categorical_encoded, columns=feature_names, index=X_train_prep.index)\n",
    "X_train_prep = pd.concat([X_train_prep.drop(columns=categorical_features), encoded_df_train], axis=1)\n",
    "\n",
    "# Transform no conjunto de teste\n",
    "categorical_encoded_test = ohe.transform(X_test_prep[categorical_features])\n",
    "encoded_df_test = pd.DataFrame(categorical_encoded_test, columns=feature_names, index=X_test_prep.index)\n",
    "X_test_prep = pd.concat([X_test_prep.drop(columns=categorical_features), encoded_df_test], axis=1)\n",
    "\n",
    "# Verificação das transformações\n",
    "print(\"\\n=== Resultado do Preprocessamento ===\")\n",
    "print(f\"\\nNúmero de features após one-hot encoding: {X_train_prep.shape[1]}\")\n",
    "print(\"\\nNovas variáveis categóricas:\")\n",
    "print([col for col in X_train_prep.columns if any(f in col for f in categorical_features)])\n",
    "\n",
    "# Exibição dos primeiros registros do DataFrame transformado\n",
    "print(\"\\n=== Primeiros 10 registros após transformação ===\")\n",
    "print(X_train_prep.head(10))\n",
    "\n",
    "# Guardar os nomes das colunas para uso posterior\n",
    "column_names = X_train_prep.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento das variáveis numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização das variáveis numéricas\n",
    "\n",
    "# Definição das variáveis numéricas e seus respectivos scalers\n",
    "numeric_features = {\n",
    "    'standard': ['IDADE', 'NPARC'],  # Variáveis com distribuição aproximadamente normal\n",
    "    'robust': ['RENDA', 'VBEM', 'VPARC', 'ENTRADA'],  # Variáveis com outliers\n",
    "    'minmax': ['RESMS']  # Variável temporal com limite natural\n",
    "}\n",
    "\n",
    "# Copia dos dataframes já processados anteriormente\n",
    "X_train_final = X_train_prep.copy()\n",
    "X_test_final = X_test_prep.copy()\n",
    "\n",
    "# Dicionário para armazenar os scalers\n",
    "scalers = {}\n",
    "\n",
    "# Aplicar StandardScaler\n",
    "std_scaler = StandardScaler()\n",
    "for col in numeric_features['standard']:\n",
    "    scalers[col] = std_scaler\n",
    "    X_train_final[col] = std_scaler.fit_transform(X_train_final[[col]])\n",
    "    X_test_final[col] = std_scaler.transform(X_test_final[[col]])\n",
    "\n",
    "# Aplicar RobustScaler\n",
    "rob_scaler = RobustScaler()\n",
    "for col in numeric_features['robust']:\n",
    "    scalers[col] = rob_scaler\n",
    "    X_train_final[col] = rob_scaler.fit_transform(X_train_final[[col]])\n",
    "    X_test_final[col] = rob_scaler.transform(X_test_final[[col]])\n",
    "\n",
    "# Aplicar MinMaxScaler\n",
    "mm_scaler = MinMaxScaler()\n",
    "for col in numeric_features['minmax']:\n",
    "    scalers[col] = mm_scaler\n",
    "    X_train_final[col] = mm_scaler.fit_transform(X_train_final[[col]])\n",
    "    X_test_final[col] = mm_scaler.transform(X_test_final[[col]])\n",
    "\n",
    "# Verificação dos intervalos de valores antes/depois da normalização\n",
    "all_features = (numeric_features['standard'] + \n",
    "                numeric_features['robust'] + \n",
    "                numeric_features['minmax'])\n",
    "\n",
    "print(\"\\n=== Intervalos de valores antes/depois da normalização ===\")\n",
    "for feature in all_features:\n",
    "    print(f\"\\nFeature: {feature}\")\n",
    "    print(f\"Original     - min: {df_train[feature].min():10.2f}, max: {df_train[feature].max():10.2f}\")\n",
    "    print(f\"Normalizado - min: {X_train_final[feature].min():10.2f}, max: {X_train_final[feature].max():10.2f}\")\n",
    "    print(f\"Scaler usado: {scalers[feature].__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento e resultados com os modelos propostos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização dos modelos\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Dicionários para armazenar resultados\n",
    "results = {}\n",
    "\n",
    "# Criar figura única para todas as curvas ROC\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Cores para cada modelo\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "for (name, model), color in zip(models.items(), colors):\n",
    "    # Treinar modelo\n",
    "    model.fit(X_train_final, y_train)\n",
    "    \n",
    "    # Obter probabilidades de predição\n",
    "    y_prob = model.predict_proba(X_test_final)[:, 1]\n",
    "    \n",
    "    # Calcular curva ROC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Calcular F1-scores para diferentes limiares\n",
    "    f1_scores = []\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    # Encontrar limiar ótimo\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    \n",
    "    # Plotar curva ROC\n",
    "    plt.plot(fpr, tpr, color=color, lw=2,\n",
    "             label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    # Marcar ponto do limiar ótimo\n",
    "    plt.plot(fpr[optimal_idx], tpr[optimal_idx], 'o', color=color,\n",
    "             label=f'{name} optimal threshold\\n(F1={f1_scores[optimal_idx]:.2f})')\n",
    "    \n",
    "    # Calcular predições com limiar ótimo\n",
    "    y_pred_optimal = (y_prob >= optimal_threshold).astype(int)\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    results[name] = {\n",
    "        'threshold': optimal_threshold,\n",
    "        'predictions': y_pred_optimal,\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred_optimal),\n",
    "        'classification_report': classification_report(y_test, y_pred_optimal)\n",
    "    }\n",
    "\n",
    "# Finalizar gráfico ROC\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Comparação das Curvas ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotar matrizes de confusão\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for idx, (name, result) in enumerate(results.items()):\n",
    "    sns.heatmap(result['confusion_matrix'], annot=True, fmt='d', cmap='Blues', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{name}\\nThreshold = {result[\"threshold\"]:.2f}')\n",
    "    axes[idx].set_xlabel('Predicted')\n",
    "    axes[idx].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Exibir classification reports\n",
    "print(\"\\n=== Classification Reports ===\")\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Threshold: {result['threshold']:.3f}\")\n",
    "    print(result['classification_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Predição de preços de diamantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise exploratória da base fornecida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset diamonds\n",
    "df = pd.read_csv('data/diamonds.csv')\n",
    "\n",
    "# Análise inicial dos dados\n",
    "print(\"=== Informações gerais do dataset ===\")\n",
    "print(df.info())\n",
    "\n",
    "# Remove a coluna Unnamed: 0 e separa features de target\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Divisão em conjuntos de treino e teste (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verificação dos conjuntos\n",
    "print(\"=== Dimensões dos conjuntos ===\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "# Verificação da distribuição da variável target\n",
    "print(\"\\n=== Estatísticas da variável target ===\")\n",
    "print(\"\\nConjunto de treino:\")\n",
    "print(y_train.describe())\n",
    "print(\"\\nConjunto de teste:\")\n",
    "print(y_test.describe())\n",
    "\n",
    "# Distribuição da variável target (price)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='price', kde=True)\n",
    "plt.title('Distribuição dos Preços')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise das variáveis categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise das variáveis categóricas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Definição das variáveis categóricas\n",
    "categorical_features = ['cut', 'color', 'clarity']\n",
    "\n",
    "# Criar subplots para visualizar a distribuição de cada variável categórica\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, feature in enumerate(categorical_features):\n",
    "    # Calcular contagens e ordenar por frequência\n",
    "    value_counts = X_train[feature].value_counts().sort_values(ascending=True)\n",
    "    \n",
    "    # Plotar barras horizontais\n",
    "    sns.barplot(x=value_counts.values, y=value_counts.index, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Distribuição de {feature}')\n",
    "    axes[idx].set_xlabel('Contagem')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Exibir cardinalidade de cada variável\n",
    "print(\"\\n=== Cardinalidade das variáveis categóricas ===\")\n",
    "for feature in categorical_features:\n",
    "    n_unique = X_train[feature].nunique()\n",
    "    print(f\"{feature}: {n_unique} valores únicos\")\n",
    "    print(\"Valores:\", sorted(X_train[feature].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificação da ordenação das categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise das variáveis categóricas ordinais e verificação da ordem\n",
    "categorical_features = {\n",
    "    'cut': ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal'],  # Qualidade do corte\n",
    "    'color': ['J', 'I', 'H', 'G', 'F', 'E', 'D'],  # D é a melhor (incolor)\n",
    "    'clarity': ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']  # IF é a melhor\n",
    "}\n",
    "\n",
    "# Verificar ordenação das categorias\n",
    "print(\"\\n=== Verificação da ordenação das categorias ===\")\n",
    "print(\"Nota: A ordem das categorias nos dados não segue a ordem natural do domínio.\")\n",
    "print(\"Isso reforça a necessidade de usar OneHotEncoder em vez de codificação ordinal.\")\n",
    "\n",
    "for feature, ordered_categories in categorical_features.items():\n",
    "    actual_categories = sorted(X_train[feature].unique())\n",
    "    print(f\"\\nVerificando ordem de {feature}:\")\n",
    "    print(f\"Ordem natural: {ordered_categories}\")\n",
    "    print(f\"Ordem nos dados: {actual_categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação do One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das variáveis categóricas\n",
    "categorical_features = ['cut', 'color', 'clarity']\n",
    "\n",
    "# One-Hot Encoding para variáveis categóricas\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "# Fit e transform no conjunto de treino\n",
    "categorical_encoded = ohe.fit_transform(X_train[categorical_features])\n",
    "\n",
    "# Criar nomes para as novas colunas\n",
    "feature_names = []\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    categories = ohe.categories_[i][1:]  # Excluindo a primeira categoria (drop='first')\n",
    "    feature_names.extend([f\"{feature}_{cat}\" for cat in categories])\n",
    "\n",
    "# Adicionar colunas encoded ao DataFrame de treino\n",
    "encoded_df_train = pd.DataFrame(categorical_encoded, columns=feature_names, index=X_train.index)\n",
    "X_train_encoded = pd.concat([X_train.drop(columns=categorical_features), encoded_df_train], axis=1)\n",
    "\n",
    "# Transform no conjunto de teste\n",
    "categorical_encoded_test = ohe.transform(X_test[categorical_features])\n",
    "encoded_df_test = pd.DataFrame(categorical_encoded_test, columns=feature_names, index=X_test.index)\n",
    "X_test_encoded = pd.concat([X_test.drop(columns=categorical_features), encoded_df_test], axis=1)\n",
    "\n",
    "# Verificação das transformações\n",
    "print(\"=== Resultado do Preprocessamento ===\")\n",
    "print(f\"\\nNúmero de features após one-hot encoding: {X_train_encoded.shape[1]}\")\n",
    "print(\"\\nNovas variáveis categóricas:\")\n",
    "print([col for col in X_train_encoded.columns if any(f in col for f in categorical_features)])\n",
    "\n",
    "# Exibição dos primeiros registros do DataFrame transformado\n",
    "print(\"\\n=== Primeiros 5 registros após transformação ===\")\n",
    "print(\"\\nVariáveis numéricas e dummies:\")\n",
    "print(X_train_encoded.head())\n",
    "\n",
    "# Exibir algumas estatísticas das novas features\n",
    "print(\"\\n=== Resumo das novas features categóricas ===\")\n",
    "dummy_cols = [col for col in X_train_encoded.columns if any(f in col for f in categorical_features)]\n",
    "print(X_train_encoded[dummy_cols].describe().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento das variáveis numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização das variáveis numéricas\n",
    "\n",
    "# Definição das variáveis numéricas e seus respectivos scalers\n",
    "numeric_features = {\n",
    "    'standard': ['depth', 'table'],  # Variáveis com distribuição aproximadamente normal\n",
    "    'robust': ['carat'],            # Variáveis com outliers\n",
    "    'minmax': ['x', 'y', 'z']      # Variáveis de dimensão com limites naturais\n",
    "}\n",
    "\n",
    "# Copia dos dataframes já processados anteriormente\n",
    "X_train_final = X_train_encoded.copy()\n",
    "X_test_final = X_test_encoded.copy()\n",
    "\n",
    "# Dicionário para armazenar os scalers\n",
    "scalers = {}\n",
    "\n",
    "# Aplicar StandardScaler para variáveis com distribuição normal\n",
    "std_scaler = StandardScaler()\n",
    "for col in numeric_features['standard']:\n",
    "    scalers[col] = std_scaler\n",
    "    X_train_final[col] = std_scaler.fit_transform(X_train_final[[col]])\n",
    "    X_test_final[col] = std_scaler.transform(X_test_final[[col]])\n",
    "\n",
    "# Aplicar RobustScaler para variáveis com outliers\n",
    "rob_scaler = RobustScaler()\n",
    "for col in numeric_features['robust']:\n",
    "    scalers[col] = rob_scaler\n",
    "    X_train_final[col] = rob_scaler.fit_transform(X_train_final[[col]])\n",
    "    X_test_final[col] = rob_scaler.transform(X_test_final[[col]])\n",
    "\n",
    "# Aplicar MinMaxScaler para variáveis com limites naturais\n",
    "mm_scaler = MinMaxScaler()\n",
    "for col in numeric_features['minmax']:\n",
    "    scalers[col] = mm_scaler\n",
    "    X_train_final[col] = mm_scaler.fit_transform(X_train_final[[col]])\n",
    "    X_test_final[col] = mm_scaler.transform(X_test_final[[col]])\n",
    "\n",
    "# Verificação dos intervalos antes/depois\n",
    "print(\"\\n=== Intervalos de valores antes/depois da normalização ===\")\n",
    "for feature in sum(numeric_features.values(), []):\n",
    "    print(f\"\\nFeature: {feature}\")\n",
    "    print(f\"Original     - min: {X_train[feature].min():10.2f}, max: {X_train[feature].max():10.2f}\")\n",
    "    print(f\"Normalizado - min: {X_train_final[feature].min():10.2f}, max: {X_train_final[feature].max():10.2f}\")\n",
    "    print(f\"Scaler usado: {scalers[feature].__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento aplicando os algoritmos propostos com avaliação dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Inicializa os modelos\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Treina e avalia os modelos\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Treina o modelo\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    model.fit(X_train_final, y_train)\n",
    "    \n",
    "    # Faz previsões\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    \n",
    "    # Calcula métricas\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Armazena resultados\n",
    "    results[name] = {\n",
    "        'R2': r2,\n",
    "        'RMSE': rmse\n",
    "    }\n",
    "    \n",
    "    print(f\"Resultados para {name}:\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# Plotagem dos resultados (Actual vs Predicted)\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, (name, model) in enumerate(models.items(), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Valor Real')\n",
    "    plt.ylabel('Valor Predito')\n",
    "    plt.title(f'{name}\\nR² = {results[name][\"R2\"]:.4f}\\nRMSE = {results[name][\"RMSE\"]:.0f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotagem dos resíduos\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, (name, model) in enumerate(models.items(), 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    residuals = y_test - y_pred\n",
    "    plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Valor Predito')\n",
    "    plt.ylabel('Resíduos')\n",
    "    plt.title(f'{name} - Análise de Resíduos')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Conjuntos desbalanceados - parte I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruções iniciais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intruções Iniciais\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "f = open('data/A652.pickle', 'rb')\n",
    "\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test) = pickle.load(f)\n",
    "print (f\"Shapes: \", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando a base em Pandas para maior flexibilidade   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação dos tamanhos dos conjuntos\n",
    "print(\"=== Tamanho dos Conjuntos de Dados originais (A652.pickle) ===\")\n",
    "print(f\"X_train: {X_train.shape} amostras, {X_train.shape[1]} features\")\n",
    "print(f\"X_val:   {X_val.shape} amostras, {X_val.shape[1]} features\")\n",
    "print(f\"X_test:  {X_test.shape} amostras, {X_test.shape[1]} features\")\n",
    "\n",
    "\n",
    "# Transforma em dataframe\n",
    "X_train = pd.DataFrame(X_train, columns=[f'feature_{i}' for i in range(X_train.shape[1])])\n",
    "X_val = pd.DataFrame(X_val, columns=[f'feature_{i}' for i in range(X_val.shape[1])])\n",
    "X_test = pd.DataFrame(X_test, columns=[f'feature_{i}' for i in range(X_test.shape[1])])\n",
    "\n",
    "\n",
    "print(\"Train class distribution:\")\n",
    "print(pd.Series(y_train.ravel()).value_counts(normalize=True))\n",
    "print(\"\\nValidation class distribution:\")\n",
    "print(pd.Series(y_val.ravel()).value_counts(normalize=True))\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(pd.Series(y_test.ravel()).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformação para um problema de classificação com análise de balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando rótulos binários\n",
    "y_train_binary = (y_train != 0).astype(int)\n",
    "y_val_binary = (y_val != 0).astype(int)\n",
    "y_test_binary = (y_test != 0).astype(int)\n",
    "\n",
    "# Verificando a distribuição das classes\n",
    "print(\"=== Distribuição das Classes ===\")\n",
    "print(\"\\nConjunto de Treinamento:\")\n",
    "print(pd.Series(y_train_binary.ravel()).value_counts(normalize=True))\n",
    "print(\"\\nConjunto de Validação:\")\n",
    "print(pd.Series(y_val_binary.ravel()).value_counts(normalize=True))\n",
    "print(\"\\nConjunto de Teste:\")\n",
    "print(pd.Series(y_test_binary.ravel()).value_counts(normalize=True))\n",
    "\n",
    "# Plotando a distribuição das classes\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.pie(pd.Series(y_train_binary.ravel()).value_counts(), \n",
    "    labels=['Classe 0', 'Classe 1'],\n",
    "    autopct='%1.1f%%')\n",
    "plt.title('Distribuição - Treino')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.pie(pd.Series(y_val_binary.ravel()).value_counts(), \n",
    "    labels=['Classe 0', 'Classe 1'],\n",
    "    autopct='%1.1f%%')\n",
    "plt.title('Distribuição - Validação')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.pie(pd.Series(y_test_binary.ravel()).value_counts(), \n",
    "    labels=['Classe 0', 'Classe 1'],\n",
    "    autopct='%1.1f%%')\n",
    "plt.title('Distribuição - Teste')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação do Gradient Boosting e comparação dos resultados entre o modelo base e os modelos com undersampling, oversampling e ajuste de limiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo base (sem balanceamento)\n",
    "base_model = GradientBoostingClassifier(random_state=42)\n",
    "base_model.fit(X_train, y_train_binary.ravel())\n",
    "\n",
    "# Predições\n",
    "base_pred = base_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Undersampling - Reduzindo a classe majoritária\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_under, y_train_under = rus.fit_resample(X_train, y_train_binary.ravel())\n",
    "\n",
    "# Treinamento do  modelo com undersampling\n",
    "under_model = GradientBoostingClassifier(random_state=42)\n",
    "under_model.fit(X_train_under, y_train_under)\n",
    "\n",
    "# Predições\n",
    "under_pred = under_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Oversampling - Aumentando a classe minoritária\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train_binary.ravel())\n",
    "\n",
    "# Treinamento do modelo com oversampling\n",
    "over_model = GradientBoostingClassifier(random_state=42)\n",
    "over_model.fit(X_train_over, y_train_over)\n",
    "\n",
    "# Predições\n",
    "over_pred = over_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Alteração de limiar - usando probabilidades do modelo base\n",
    "# Encontrar melhor limiar usando F1-score\n",
    "thresholds = np.arange(0.1, 0.9, 0.1)\n",
    "f1_scores = []\n",
    "\n",
    "# Usar conjunto de validação para ajustar o limiar\n",
    "val_probs = base_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "for threshold in thresholds:\n",
    "    val_pred = (val_probs >= threshold).astype(int)\n",
    "    f1 = f1_score(y_val_binary, val_pred)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Encontrar melhor limiar com base no conjunto de validação\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "\n",
    "# Aplicar o limiar otimizado no conjunto de teste\n",
    "test_probs = base_model.predict_proba(X_test)[:, 1]\n",
    "threshold_pred = (test_probs >= best_threshold).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# Plotar matrizes de confusão\n",
    "plt.figure(figsize=(12, 6))\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "titles = ['Base Model', 'Undersampling', 'Oversampling (SMOTE)', f'Threshold ({best_threshold:.2f})']\n",
    "predictions = [base_pred, under_pred, over_pred, threshold_pred]\n",
    "\n",
    "for ax, title, pred in zip(axes.ravel(), titles, predictions):\n",
    "    sns.heatmap(confusion_matrix(y_test_binary, pred), annot=True, fmt='d', ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Criação da tabela de comparação\n",
    "metrics = {\n",
    "    'Model': ['Base Model', 'Undersampling', 'Oversampling (SMOTE)', 'Threshold'],\n",
    "    'Accuracy': [],\n",
    "    'Precision (Class 1)': [], \n",
    "    'Recall (Class 1)': [],\n",
    "    'F1-score (Class 1)': []\n",
    "}\n",
    "\n",
    "# Base model metrics\n",
    "base_report = classification_report(y_test_binary, base_pred, output_dict=True)\n",
    "metrics['Accuracy'].append(base_report['accuracy'])\n",
    "metrics['Precision (Class 1)'].append(base_report['1']['precision'])\n",
    "metrics['Recall (Class 1)'].append(base_report['1']['recall'])\n",
    "metrics['F1-score (Class 1)'].append(base_report['1']['f1-score'])\n",
    "\n",
    "# Undersampling metrics\n",
    "under_report = classification_report(y_test_binary, under_pred, output_dict=True)\n",
    "metrics['Accuracy'].append(under_report['accuracy'])\n",
    "metrics['Precision (Class 1)'].append(under_report['1']['precision'])\n",
    "metrics['Recall (Class 1)'].append(under_report['1']['recall'])\n",
    "metrics['F1-score (Class 1)'].append(under_report['1']['f1-score'])\n",
    "\n",
    "# Oversampling metrics\n",
    "over_report = classification_report(y_test_binary, over_pred, output_dict=True)\n",
    "metrics['Accuracy'].append(over_report['accuracy'])\n",
    "metrics['Precision (Class 1)'].append(over_report['1']['precision'])\n",
    "metrics['Recall (Class 1)'].append(over_report['1']['recall'])\n",
    "metrics['F1-score (Class 1)'].append(over_report['1']['f1-score'])\n",
    "\n",
    "# Threshold metrics\n",
    "thresh_report = classification_report(y_test_binary, threshold_pred, output_dict=True)\n",
    "metrics['Accuracy'].append(thresh_report['accuracy'])\n",
    "metrics['Precision (Class 1)'].append(thresh_report['1']['precision'])\n",
    "metrics['Recall (Class 1)'].append(thresh_report['1']['recall'])\n",
    "metrics['F1-score (Class 1)'].append(thresh_report['1']['f1-score'])\n",
    "\n",
    "# Criação do DataFrame para exibição\n",
    "comparison_df = pd.DataFrame(metrics)\n",
    "print(\"\\nComparação dos resultados encontrados:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Conjuntos desbalanceados - parte II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecionando as bases e distribuições originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "f = open('data/A652.pickle', 'rb')\n",
    "\n",
    "(X_train, y_train, X_val, y_val, X_test, y_test) = pickle.load(f)\n",
    "print (f\"Shapes: \", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "f.close()\n",
    "\n",
    "\n",
    "\n",
    "# Verificação dos tamanhos dos conjuntos\n",
    "print(\"=== Tamanho dos Conjuntos de Dados originais (A652.pickle) ===\")\n",
    "print(f\"X_train: {X_train.shape} amostras, {X_train.shape[1]} features\")\n",
    "print(f\"X_val:   {X_val.shape} amostras, {X_val.shape[1]} features\")\n",
    "print(f\"X_test:  {X_test.shape} amostras, {X_test.shape[1]} features\")\n",
    "\n",
    "print(\"Train class distribution:\")\n",
    "print(pd.Series(y_train.ravel()).value_counts(normalize=True))\n",
    "print(\"\\nValidation class distribution:\")\n",
    "print(pd.Series(y_val.ravel()).value_counts(normalize=True))\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(pd.Series(y_test.ravel()).value_counts(normalize=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando versões binárias das matrizes alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando rótulos binários\n",
    "y_train_bin = (y_train != 0).astype(int)\n",
    "y_val_bin = (y_val != 0).astype(int)\n",
    "y_test_bin = (y_test != 0).astype(int)\n",
    "\n",
    "# Verificando a distribuição das classes\n",
    "print(\"=== Distribuição das Classes ===\")\n",
    "print(\"\\nConjunto de Treinamento:\")\n",
    "print(pd.Series(y_train_bin.ravel()).value_counts(normalize=True))\n",
    "print(\"\\nConjunto de Validação:\")\n",
    "print(pd.Series(y_val_bin.ravel()).value_counts(normalize=True))\n",
    "print(\"\\nConjunto de Teste:\")\n",
    "print(pd.Series(y_test_bin.ravel()).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando o modelo C usando o Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Treinar modelo C usando conjunto de treinamento\n",
    "C = GradientBoostingClassifier(random_state=42)\n",
    "C.fit(X_train, y_train_bin.ravel())\n",
    "\n",
    "# 2. Aplicar C ao conjunto de validação\n",
    "val_probs = C.predict_proba(X_val)[:, 1]  # Probabilidades da classe positiva\n",
    "val_pred = C.predict(X_val)  # Predições usando threshold padrão (0.5)\n",
    "\n",
    "# Exibir resultados iniciais no conjunto de validação\n",
    "print(\"=== Resultados no conjunto de validação ===\")\n",
    "print(\"\\nMatriz de confusão:\")\n",
    "print(confusion_matrix(y_val_bin, val_pred))\n",
    "print(\"\\nRelatório de classificação:\")\n",
    "print(classification_report(y_val_bin, val_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando os subconjuntos para o grupo classificado por C como classe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and probabilities from model C for X_val\n",
    "#val_pred = C.predict(X_val)\n",
    "#val_probs = C.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Create mask for samples classified as class 1\n",
    "mask_classe_1 = (val_pred == 1)\n",
    "\n",
    "# Define X_train_1 and y_train_1 using the mask\n",
    "X_train_1 = X_val[mask_classe_1]\n",
    "y_train_1 = y_val_bin[mask_classe_1]\n",
    "\n",
    "# Print information about the subsets\n",
    "print(\"=== Tamanho dos subconjuntos ===\")\n",
    "print(f\"X_val original: {X_val.shape}\")\n",
    "print(f\"X_train_1: {X_train_1.shape}\")\n",
    "print(\"\\nDistribuição das classes em y_train_1:\")\n",
    "print(pd.Series(y_train_1.ravel()).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando o modelo R para a regressão dos subconjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo de regressão R usando X_train_1\n",
    "# Importando o modelo de regressão\n",
    "\n",
    "\n",
    "# Treinamento do modelo de regressão R usando X_train_1 \n",
    "R = GradientBoostingRegressor(random_state=42)\n",
    "R.fit(X_train_1, y_train_1.ravel())\n",
    "\n",
    "# Verificação básica do modelo\n",
    "print(\"=== Modelo de Regressão R ===\")\n",
    "print(f\"Treinado com {X_train_1.shape[0]} amostras\")\n",
    "print(f\"Número de features: {X_train_1.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computando C(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar o classificador no conjunto de teste\n",
    "y_test_pred_class = C.predict(X_test).ravel()\n",
    "print(\"\\n=== Computando inicialmente C(x)  ===\")\n",
    "print(pd.Series(y_test_pred_class).value_counts(normalize=False))\n",
    "\n",
    "# Prever valores de precipitação usando o modelo combinado\n",
    "y_test_pred_final = np.where(\n",
    "    y_test_pred_class == 0,\n",
    "    0,\n",
    "    R.predict(X_test).ravel()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo R' (y_test_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar máscara para valores positivos (onde C(x) = 1)\n",
    "positive_mask = (y_test_pred_class == 1)\n",
    "\n",
    "# Inicializar array final com zeros\n",
    "y_test_pred_final = np.zeros_like(y_test.ravel())\n",
    "\n",
    "# Aplicar modelo R apenas onde C(x) = 1\n",
    "if np.sum(positive_mask) > 0:\n",
    "    y_test_pred_final[positive_mask] = R.predict(X_test[positive_mask]).ravel()\n",
    "\n",
    "# Análise dos resultados\n",
    "print(\"\\n=== Distribuição das Predições ===\")\n",
    "print(f\"Total de amostras: {len(y_test_pred_class)}\")\n",
    "print(f\"Amostras com C(x) = 0: {np.sum(y_test_pred_class == 0)}\")\n",
    "print(f\"Amostras com C(x) = 1: {np.sum(y_test_pred_class == 1)}\")\n",
    "\n",
    "\n",
    "\n",
    "# 4.4 Avaliação do desempenho por nível de severidade\n",
    "def classificar_severidade(valor):\n",
    "    if valor < 5:\n",
    "        return \"Sem Chuva/Leve\"\n",
    "    elif valor < 25:\n",
    "        return \"Moderada\"\n",
    "    elif valor < 50:\n",
    "        return \"Forte\"\n",
    "    else:\n",
    "        return \"Tempestade\"\n",
    "\n",
    "# Aplicar classificação de severidade\n",
    "severidades = np.vectorize(classificar_severidade)(y_test.ravel())\n",
    "\n",
    "# Avaliar RMSE por nível de severidade\n",
    "print(\"\\nAvaliação por nível de severidade:\")\n",
    "for nivel in [\"Sem Chuva/Leve\", \"Moderada\", \"Forte\", \"Tempestade\"]:\n",
    "    idx = severidades == nivel\n",
    "    if np.sum(idx) > 0:\n",
    "        rmse_nivel = np.sqrt(mean_squared_error(y_test.ravel()[idx], y_test_pred_final[idx]))\n",
    "        n_amostras = np.sum(idx)\n",
    "        print(f\"{nivel:10} - RMSE: {rmse_nivel:.4f} ({n_amostras} amostras)\")\n",
    "    else:\n",
    "        print(f\"{nivel:10} - Sem amostras suficientes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a full regression model (R_full) on all data\n",
    "R_full = GradientBoostingRegressor(random_state=42)\n",
    "R_full.fit(X_train, y_train.ravel())\n",
    "\n",
    "# Get predictions from full model\n",
    "y_test_pred_R_full = R_full.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for both models\n",
    "rmse_combined = np.sqrt(mean_squared_error(y_test, y_test_pred_final))\n",
    "rmse_full = np.sqrt(mean_squared_error(y_test, y_test_pred_R_full))\n",
    "\n",
    "print(\"=== Comparação dos Modelos ===\")\n",
    "print(f\"RMSE do modelo combinado (C+R): {rmse_combined:.4f}\")\n",
    "print(f\"RMSE do modelo regressão completo: {rmse_full:.4f}\")\n",
    "print(f\"\\nDiferença percentual: {abs(rmse_combined - rmse_full)/min(rmse_combined, rmse_full)*100:.2f}%\")\n",
    "print(f\"Melhor modelo: {'Combinado (C+R)' if rmse_combined < rmse_full else 'Regressão Completa'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Calibração de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigando os modelos originais para calibração com Isotonic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# Carregar os dados\n",
    "col_names = [f'X{i}' for i in range(1, 12)] + ['y']\n",
    "df_train = pd.read_csv('data/credtrain.txt', sep=r'\\s+', header=None, names=col_names)\n",
    "df_test = pd.read_csv('data/credtest.txt', sep=r'\\s+', header=None, names=col_names)\n",
    "\n",
    "X_train, y_train = df_train.drop('y', axis=1), df_train['y']\n",
    "X_test, y_test = df_test.drop('y', axis=1), df_test['y']\n",
    "\n",
    "# Modelos base\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=5000, solver='lbfgs'), \n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# Cores com bom contraste\n",
    "colors = {\n",
    "    'LogisticRegression': '#1f77b4',   # Azul escuro\n",
    "    'KNeighborsClassifier': '#d62728', # Vermelho forte\n",
    "    'GradientBoostingClassifier': '#ff7f0e'  # Laranja\n",
    "}\n",
    "\n",
    "# Para armazenar brier scores\n",
    "brier_scores = {'Modelo': [], 'Antes': [], 'Depois': []}\n",
    "\n",
    "# Preparar figura com 2 subplots verticais\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "# Modelos Originais\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    prob_pos = model.predict_proba(X_test)[:, 1]\n",
    "    frac_pos, mean_pred = calibration_curve(y_test, prob_pos, n_bins=10)\n",
    "    axes[0].plot(mean_pred, frac_pos, marker='o', color=colors[name], label=f'{name} (orig)')\n",
    "    brier_before = brier_score_loss(y_test, prob_pos)\n",
    "    brier_scores['Modelo'].append(name)\n",
    "    brier_scores['Antes'].append(brier_before)\n",
    "\n",
    "axes[0].plot([0, 1], [0, 1], 'r--', label='Ideal')\n",
    "axes[0].set_title('Modelos Originais')\n",
    "axes[0].set_ylabel('Fraction of Positives')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Modelos Calibrados\n",
    "for name, model in models.items():\n",
    "    calibrated = CalibratedClassifierCV(model, method='isotonic', cv=5)\n",
    "    calibrated.fit(X_train, y_train)\n",
    "    prob_cal = calibrated.predict_proba(X_test)[:, 1]\n",
    "    frac_pos, mean_pred = calibration_curve(y_test, prob_cal, n_bins=10)\n",
    "    axes[1].plot(mean_pred, frac_pos, marker='o', color=colors[name], label=f'{name} (calibrado)')\n",
    "    brier_after = brier_score_loss(y_test, prob_cal)\n",
    "    brier_scores['Depois'].append(brier_after)\n",
    "\n",
    "axes[1].plot([0, 1], [0, 1], 'r--', label='Ideal')\n",
    "axes[1].set_title('Modelos Após Calibração (Isotonic)')\n",
    "axes[1].set_xlabel('Mean Predicted Probability')\n",
    "axes[1].set_ylabel('Fraction of Positives')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"calibracao_modelos.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Dataframe para Brier Scores\n",
    "df_brier = pd.DataFrame(brier_scores)\n",
    "df_brier = df_brier.sort_values(by='Depois')\n",
    "\n",
    "# Adicionar cálculo do ganho relativo\n",
    "df_brier['Ganho Relativo (%)'] = ((df_brier['Antes'] - df_brier['Depois']) / df_brier['Antes'] * 100).round(1)\n",
    "df_brier['Depois'] = df_brier.apply(lambda row: f\"{row['Depois']:.4f} ({row['Ganho Relativo (%)']:.1f}%)\", axis=1)\n",
    "df_brier['Antes'] = df_brier['Antes'].apply(lambda x: f\"{x:.4f}\")  # Formatar para 4 casas\n",
    "df_brier = df_brier.drop(columns=['Ganho Relativo (%)'])\n",
    "\n",
    "print(\"\\n Tabela Comparativa de Brier Scores (ordenada):\")\n",
    "print(df_brier.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Validação cruzada aninhada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.drop('price', axis=1)\n",
    "    y = df['price'].values\n",
    "    return X, y\n",
    "\n",
    "def build_pipeline(categorical_features, numeric_features):\n",
    "    # ColumnTransformer para pré-processamento\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features),\n",
    "        ('std', StandardScaler(), numeric_features['standard']),\n",
    "        ('robust', RobustScaler(), numeric_features['robust']),\n",
    "        ('minmax', MinMaxScaler(), numeric_features['minmax'])\n",
    "    ], remainder='drop')\n",
    "\n",
    "    # Pipelines para cada estimador\n",
    "    pipe_lr = Pipeline([\n",
    "        ('preproc', preprocessor),\n",
    "        ('model', LinearRegression())\n",
    "    ])\n",
    "    pipe_gbr = Pipeline([\n",
    "        ('preproc', preprocessor),\n",
    "        ('model', GradientBoostingRegressor(random_state=42))\n",
    "    ])\n",
    "\n",
    "    return pipe_lr, pipe_gbr\n",
    "\n",
    "def nested_cv(X, y, pipe_lr, pipe_gbr, numeric_features, categorical_features):\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    # Grid e Randomized Search\n",
    "    lr_param_grid = {\n",
    "        'model__fit_intercept': [True, False]\n",
    "    }\n",
    "    gbr_param_dist = {\n",
    "        'model__n_estimators': [100, 200, 300, 400],\n",
    "        'model__max_depth': [3, 4, 5, 6],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'model__subsample': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "\n",
    "    lr_search = GridSearchCV(pipe_lr, lr_param_grid, cv=inner_cv, scoring='r2', n_jobs=-1)\n",
    "    gbr_search = RandomizedSearchCV(pipe_gbr, gbr_param_dist, \n",
    "                                    n_iter=10, cv=inner_cv, scoring='r2', \n",
    "                                    random_state=42, n_jobs=-1)\n",
    "\n",
    "    results = []\n",
    "    for name, search in [('LinearRegression', lr_search), ('GradientBoostingRegressor', gbr_search)]:\n",
    "        for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            search.fit(X_train, y_train)\n",
    "            best = search.best_estimator_\n",
    "            preds = best.predict(X_test)\n",
    "            score = r2_score(y_test, preds)\n",
    "\n",
    "            results.append({\n",
    "                'model': name,\n",
    "                'fold': fold,\n",
    "                'test_r2': score,\n",
    "                'best_params': search.best_params_\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    summary = results_df.groupby('model')['test_r2'].agg(['mean', 'std'])\n",
    "    return results_df, summary\n",
    "\n",
    "def main():\n",
    "    data_path = 'data/diamonds.csv'\n",
    "    cat_features = ['cut', 'color', 'clarity']\n",
    "    num_features = {\n",
    "        'standard': ['depth', 'table'],\n",
    "        'robust': ['carat'],\n",
    "        'minmax': ['x', 'y', 'z']\n",
    "    }\n",
    "\n",
    "    X, y = load_data(data_path)\n",
    "    pipe_lr, pipe_gbr = build_pipeline(cat_features, num_features)\n",
    "    results_df, summary = nested_cv(X, y, pipe_lr, pipe_gbr, num_features, cat_features)\n",
    "\n",
    "    print(\"=== Resultados Detalhados ===\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    print(\"\\n=== Resumo de Desempenho ===\")\n",
    "    print(summary)\n",
    "\n",
    "    # Violin plot e bar plot com erro\n",
    "    import seaborn as sns\n",
    "    plt.figure()\n",
    "    sns.violinplot(x='model', y='test_r2', data=results_df, inner='quartile')\n",
    "    plt.title('Distribuição de R2 por Modelo')\n",
    "    plt.show()\n",
    "\n",
    "    summary['mean'].plot.bar(yerr=summary['std'], capsize=4)\n",
    "    plt.ylabel('R2 Score (mean ± std)')\n",
    "    plt.title('Comparação de Desempenho Médio')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
